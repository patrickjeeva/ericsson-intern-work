{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66cecd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import pickle\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cf53c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5fd2d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize environment\n",
    "#env_name = 'CartPole-v1'\n",
    "#env_name = 'MountainCarContinuous-v0'\n",
    "#env_name = 'MountainCar-v0'\n",
    "env_name = 'Pendulum-v1'\n",
    "\n",
    "#Defining bounds for each state variable\n",
    "bounds = {'CartPole-v1' : [[-4.8, 4.8], ['-inf', 'inf'], [-0.418, 0.418], ['-inf', 'inf']], \n",
    "        'MountainCar-v0' : [['-inf', 'inf'], ['-inf', 'inf']],\n",
    "          'MountainCarContinuous-v0' : [['-inf', 'inf'], ['-inf', 'inf']],\n",
    "          'Pendulum-v1' : [[-1, 1], [-1, 1], [-8, 8]]\n",
    "         }\n",
    "\n",
    "# Create the CartPole environment\n",
    "env = gym.make(env_name)\n",
    "\n",
    "num_samples = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0855c8b6",
   "metadata": {},
   "source": [
    "# Store the data from environment in the form (state,action)-> next state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a4a61e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def add_noise(state, terminated, bound):\n",
    "    # Add noise to the next state\n",
    "    out_bound = True\n",
    "#     print(bound)\n",
    "#     print(type(bound))\n",
    "#     print(type(bound[0]))\n",
    "#     print(type(bound[0][0]))\n",
    "    while out_bound:\n",
    "        noisy_state = state + np.random.normal(loc=0, scale=1e-8, size=state.shape)  # You can adjust the scale of noise as needed\n",
    "        for i in range(len(bound)):\n",
    "            if (isinstance(bound[i][0], str) or state[i] > bound[i][0]) and (isinstance(bound[i][1], str) or state[i] < bound[i][1]):\n",
    "                out_bound = False\n",
    "            if (noisy_state[i] - state[i]) / state[i] > 0.1:\n",
    "                out_bound = True\n",
    "        if out_bound:\n",
    "            print(state)\n",
    "            print(noisy_state)\n",
    "        if terminated:\n",
    "            out_bound = False\n",
    "    return noisy_state\n",
    "\n",
    "# Function to generate episodes\n",
    "def generate_episodes(num_samples, max_episode_length, bound):\n",
    "    episodes = []\n",
    "    episode_inputs = []\n",
    "    episode_outputs = []\n",
    "    samples = []\n",
    "    sample_count = 0\n",
    "    state_size = env.observation_space.shape[0]\n",
    "\n",
    "    while sample_count < num_samples:\n",
    "        state = env.reset()[0]\n",
    "        done = False\n",
    "        episode_length = 0\n",
    "\n",
    "        while episode_length < max_episode_length:\n",
    "            # Choose a random action for exploration\n",
    "            action = env.action_space.sample()\n",
    "            next_state, reward, terminated, truncated , info = env.step(action)\n",
    "            \n",
    "            #print(type(action))\n",
    "            #print(len(action))\n",
    "            \n",
    "            if isinstance(action, int):\n",
    "                input_tensor = torch.tensor(np.concatenate((state, [action])), dtype=torch.float32)\n",
    "            elif isinstance(action, np.ndarray):\n",
    "                input_tensor = torch.tensor(np.concatenate((state, action)), dtype=torch.float32)\n",
    "            # Concatenate the current state and action\n",
    "            \n",
    "            next_state = add_noise(next_state, terminated, bound)\n",
    "            \n",
    "            output_tensor = torch.tensor(np.concatenate((next_state, [reward], [float(terminated)])), dtype=torch.float32)\n",
    "            \n",
    "            sample = list(state) + [str(action)] + [reward] + list(next_state)\n",
    "            #print(sample)\n",
    "            samples.append(sample)\n",
    "            #output_tensor = torch.tensor(next_state, dtype=torch.float32)\n",
    "\n",
    "            episode_inputs.append(input_tensor)\n",
    "            episode_outputs.append(output_tensor)\n",
    "            \n",
    "            sample_count = sample_count + 1\n",
    "            episode_length = episode_length + 1\n",
    "\n",
    "            if terminated:\n",
    "                break\n",
    "            state = next_state\n",
    "        \n",
    "\n",
    "        episodes.append((episode_inputs, episode_outputs))\n",
    "    episode_inputs = torch.stack(episode_inputs)\n",
    "    episode_outputs = torch.stack(episode_outputs)\n",
    "    df = pd.DataFrame(samples)\n",
    "    \n",
    "    columns = [f'variable_{i}' for i in range(state_size)] + ['action','reward'] + [f'nx_variable_{i}' for i in range(state_size)]\n",
    "    print(columns)\n",
    "    columns = df.columns\n",
    "    return episode_inputs, episode_outputs, df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55469ad",
   "metadata": {},
   "source": [
    "# Generating Samples for all four environments with 10k, 20k, 30k, 40k, 50k training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23d82d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeeva/anaconda3/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['variable_0', 'variable_1', 'variable_2', 'variable_3', 'action', 'reward', 'nx_variable_0', 'nx_variable_1', 'nx_variable_2', 'nx_variable_3']\n",
      "10006\n",
      "10006\n"
     ]
    }
   ],
   "source": [
    "env_names = ['CartPole-v1', 'MountainCarContinuous-v0', 'MountainCar-v0', 'Pendulum-v1']\n",
    "# env_names = ['CartPole-v1']\n",
    "\n",
    "for env_name in env_names:\n",
    "\n",
    "    env = gym.make(env_name)\n",
    "\n",
    "    for num_samples in range(10000, 55000, 10000):\n",
    "        episodes_input, episodes_output, df = generate_episodes(num_samples, 200, bounds[env_name])\n",
    "\n",
    "        num_training_samples = int(0.8 * len(episodes_input))\n",
    "\n",
    "        train_x = episodes_input[1:num_training_samples]\n",
    "        train_y = episodes_output[1:num_training_samples]\n",
    "\n",
    "        test_x = episodes_input[num_training_samples:]\n",
    "        test_y = episodes_output[num_training_samples:]\n",
    "\n",
    "\n",
    "        print(len(episodes_input))\n",
    "        print(len(episodes_output))\n",
    "\n",
    "        train_dataset = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "        test_dataset = torch.utils.data.TensorDataset(test_x, test_y)\n",
    "        \n",
    "        # Save datasets\n",
    "        with open(env_name + '_' + str(int(num_samples/1000)) + 'k_train_dataset.pkl', 'wb') as f:\n",
    "            pickle.dump(train_dataset, f)\n",
    "\n",
    "        with open(env_name + '_' + str(int(num_samples/1000)) + 'k_test_dataset.pkl', 'wb') as f:\n",
    "            pickle.dump(test_dataset, f)\n",
    "\n",
    "        df.to_csv(env_name + '_' + str(int(num_samples/1000)) + 'k_sample.csv', index=False)\n",
    "        \n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83aa182",
   "metadata": {},
   "source": [
    "## Testing values in stored Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8f3d3c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39999\n",
      "Sample 11856:\n",
      "Input: tensor([-1.6052,  2.3752,  6.8472, -0.7606])\n",
      "Output: tensor([ 1.5264,  1.0805,  6.2406, -7.2393,  0.0000])\n",
      "Sample 11857:\n",
      "Input: tensor([ 1.5264,  1.0805,  6.2406, -1.9458])\n",
      "Output: tensor([ 1.2596,  0.0835,  7.9672, -9.3669,  0.0000])\n",
      "Sample 11858:\n",
      "Input: tensor([ 1.2596,  0.0835,  7.9672, -1.0572])\n",
      "Output: tensor([ -1.3964,   1.1590,   6.9604, -11.4406,   0.0000])\n",
      "Sample 11859:\n",
      "Input: tensor([-1.3964,  1.1590,  6.9604,  0.1044])\n",
      "Output: tensor([ -0.6795,   1.1073,   8.0195, -13.7633,   0.0000])\n",
      "Sample 11860:\n",
      "Input: tensor([-0.6795,  1.1073,  8.0195, -1.3090])\n",
      "Output: tensor([ -1.4767,  -1.6258,  11.1175, -14.3073,   0.0000])\n",
      "Sample 11861:\n",
      "Input: tensor([-1.4767, -1.6258, 11.1175,  0.7687])\n",
      "Output: tensor([  0.0296,  -0.8379,   6.5337, -11.8767,   0.0000])\n",
      "Sample 11862:\n",
      "Input: tensor([ 0.0296, -0.8379,  6.5337, -0.1866])\n",
      "Output: tensor([-1.0686, -0.4587,  7.9813, -9.8577,  0.0000])\n",
      "Sample 11863:\n",
      "Input: tensor([-1.0686, -0.4587,  7.9813, -0.8348])\n",
      "Output: tensor([ 0.7393, -3.4650,  4.0524, -7.7663,  0.0000])\n",
      "Sample 11864:\n",
      "Input: tensor([ 0.7393, -3.4650,  4.0524, -0.7602])\n",
      "Output: tensor([-0.0801, -2.2223,  1.6182, -5.8304,  0.0000])\n",
      "Sample 11865:\n",
      "Input: tensor([-0.0801, -2.2223,  1.6182,  0.3250])\n",
      "Output: tensor([ 0.0399, -0.2187,  2.5937, -4.2571,  0.0000])\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "num_samples = 50000\n",
    "\n",
    "# Load the training dataset\n",
    "with open(env_name + '_' + str(int(num_samples/1000)) + 'k_train_dataset.pkl', 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "# Load the testing dataset\n",
    "with open(env_name + '_' + str(int(num_samples/1000)) + 'k_test_dataset.pkl', 'rb') as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "\n",
    "# Function to print the first 5 values of the dataset\n",
    "def print_first_5_values(dataset, dataset_name):\n",
    "#     print(f\"First 5 values of {dataset_name}:\")\n",
    "    count  = 0\n",
    "    print(len(dataset))\n",
    "    for i in range(11855, 11865):\n",
    "#         print(dataset[i])\n",
    "        input_tensor, output_tensor = dataset[i]\n",
    "        if output_tensor[-1] == 0:\n",
    "            count = count+1\n",
    "        print(f\"Sample {i + 1}:\")\n",
    "        print(\"Input:\", input_tensor)\n",
    "        print(\"Output:\", output_tensor)\n",
    "#     print(dataset[1])\n",
    "    print(count)\n",
    "\n",
    "# Print the first 5 values of the training dataset\n",
    "print_first_5_values(train_dataset, \"training dataset\")\n",
    "\n",
    "# Print the first 5 values of the testing dataset\n",
    "# print_first_5_values(test_dataset, \"testing dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0483b4a3",
   "metadata": {},
   "source": [
    "### Finding Max and Min Bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76ceb6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CartPole environment\n",
    "#env_name = 'CartPole-v1'\n",
    "#env_name = 'MountainCarContinuous-v0'\n",
    "#env_name = 'MountainCar-v0'\n",
    "env_name = 'Pendulum-v1'\n",
    "\n",
    "# Create the CartPole environment\n",
    "env = gym.make(env_name)\n",
    "\n",
    "#num_samples = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee803b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_input tensor([ 4.9642,  4.4407, 11.1886,  2.0000])\n",
      "max_label tensor([ 4.9642e+00,  4.4407e+00,  1.1189e+01, -2.9544e-04,  0.0000e+00])\n",
      "min_input tensor([ -5.1541,  -4.7110, -11.1756,  -2.0000])\n",
      "min_label tensor([ -5.1541,  -4.7110, -11.1756, -16.2625,   0.0000])\n",
      "tensor([ -4.5428,  -4.1662, -10.3733])\n",
      "tensor([ 4.9642,  4.5456, 11.1886])\n"
     ]
    }
   ],
   "source": [
    "state_size = env.observation_space.shape[0]\n",
    "\n",
    "max_value = 0\n",
    "min_value = 0\n",
    "\n",
    "\n",
    "for num_samples in range(50000, 60000, 10000):\n",
    "    with open(env_name + '_' + str(int(num_samples/1000)) + 'k_train_dataset.pkl', 'rb') as f:\n",
    "        train_dataset = pickle.load(f)\n",
    "\n",
    "    with open(env_name + '_' + str(int(num_samples/1000)) + 'k_test_dataset.pkl', 'rb') as f:\n",
    "        test_dataset = pickle.load(f)\n",
    "        \n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "    \n",
    "#     print(\"Train Data\")\n",
    "\n",
    "    for data in train_loader:\n",
    "        inputs, labels = data\n",
    "        \n",
    "        max_input = (inputs.max(dim=0)[0])\n",
    "        max_label = (labels.max(dim=0)[0])\n",
    "        \n",
    "        print('max_input', max_input)\n",
    "        print('max_label', max_label)\n",
    "        \n",
    "        max_input = max_input[:state_size]\n",
    "        max_label = max_label[:-2]\n",
    "\n",
    "#         print('max_input', max_input)\n",
    "#         print('max_label', max_label)\n",
    "\n",
    "        max_all_state = torch.max(max_input, max_label)\n",
    "\n",
    "#         print('max_all_state', max_all_state)\n",
    "\n",
    "        if isinstance(max_value, int):\n",
    "#             max_value = max_all_state\n",
    "            max_value = max_input\n",
    "        else:\n",
    "#             max_value = torch.max(max_all_state, max_value)\n",
    "            max_value = torch.max(max_input, max_value)\n",
    "#             print('max_value', max_value)\n",
    "            \n",
    "        min_input = (inputs.min(dim=0)[0])\n",
    "        min_label = (labels.min(dim=0)[0])\n",
    "        \n",
    "        print('min_input', min_input)\n",
    "        print('min_label', min_label)\n",
    "        \n",
    "        min_input = min_input[:state_size]\n",
    "        min_label = min_label[:-2]\n",
    "\n",
    "#         print('max_input', min_input)\n",
    "#         print('max_label', min_label)\n",
    "\n",
    "        min_all_state = torch.min(min_input, min_label)\n",
    "\n",
    "#         print('max_all_state', min_all_state)\n",
    "\n",
    "        if isinstance(min_value, int):\n",
    "#             min_value = min_all_state\n",
    "            min_value = min_input\n",
    "        else:\n",
    "#             min_value = torch.min(min_all_state, min_value)\n",
    "            min_value = torch.min(min_input, min_value)\n",
    "#             print('min_value', min_value)\n",
    "    \n",
    "#     print(\"Test Data\")\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        \n",
    "        max_input = (inputs.max(dim=0)[0])[:state_size]\n",
    "        max_label = (labels.max(dim=0)[0])[:-2]\n",
    "\n",
    "#         print('max_input', max_input)\n",
    "#         print('max_label', max_label)\n",
    "\n",
    "        max_all_state = torch.max(max_input, max_label)\n",
    "\n",
    "#         print('max_all_state', max_all_state)\n",
    "\n",
    "#         max_value = torch.max(max_all_state, max_value)\n",
    "        max_value = torch.max(max_input, max_value)\n",
    "#         print('max_value', max_value)   \n",
    "        \n",
    "        min_input = (inputs.min(dim=0)[0])\n",
    "        min_label = (labels.min(dim=0)[0])\n",
    "        \n",
    "#         print('min_input', min_input)\n",
    "#         print('min_label', min_label)\n",
    "        \n",
    "        min_input = min_input[:state_size]\n",
    "        min_label = min_label[:-2]\n",
    "\n",
    "#         print('max_input', min_input)\n",
    "#         print('max_label', min_label)\n",
    "\n",
    "        min_all_state = torch.min(min_input, min_label)\n",
    "\n",
    "#         print('max_all_state', min_all_state)\n",
    "\n",
    "#        min_value = torch.min(min_all_state, min_value)\n",
    "        min_value = torch.max(min_input, min_value)\n",
    "#         print('min_value', min_value)\n",
    "        \n",
    "\n",
    "print(min_value)\n",
    "print(max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02e6356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_x, test_y)\n",
    "\n",
    "# Save datasets\n",
    "with open(env_name + '_' + str(int(num_samples/1000)) + 'k_train_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump(train_dataset, f)\n",
    "\n",
    "with open(env_name + '_' + str(int(num_samples/1000)) + 'k_test_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump(test_dataset, f)\n",
    "    \n",
    "df.to_csv(env_name + '_' + str(int(num_samples/1000)) + 'k_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca09c19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
