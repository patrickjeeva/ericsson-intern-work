{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5d4ee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e9c8b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4615c457",
   "metadata": {},
   "source": [
    "## Generate samples from PETS models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aae09b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_layers, num_nodes, activation, num_ensembles):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_nodes = num_nodes\n",
    "        self.activation = activation\n",
    "        self.num_ensembles = num_ensembles\n",
    "\n",
    "        self.ensemble_models = nn.ModuleList()\n",
    "        for _ in range(num_ensembles):\n",
    "            model = self._build_model()\n",
    "            self.ensemble_models.append(model)\n",
    "\n",
    "    def _build_model(self):\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(self.input_size, self.num_nodes))\n",
    "        layers.append(self.activation)\n",
    "\n",
    "        for _ in range(self.num_layers - 1):\n",
    "            layers.append(nn.Linear(self.num_nodes, self.num_nodes))\n",
    "            layers.append(self.activation)\n",
    "\n",
    "        layers.append(nn.Linear(self.num_nodes, self.output_size))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        means = []\n",
    "        stds = []\n",
    "        for model in self.ensemble_models:\n",
    "            output = model(x)\n",
    "            mean = output[:, :self.output_size // 2]\n",
    "            std = torch.exp(output[:, self.output_size // 2:])\n",
    "            means.append(mean)\n",
    "            stds.append(std)\n",
    "        means = torch.stack(means, dim=0)\n",
    "        stds = torch.stack(stds, dim=0)\n",
    "        final_mean = torch.mean(means, dim=0)\n",
    "        final_std = torch.mean(stds, dim=0)\n",
    "        return final_mean, final_std\n",
    "    \n",
    "# Loss function\n",
    "def gaussian_likelihood(mean_pred, std_pred, target):\n",
    "    EPS = 1e-6 \n",
    "    std_pred = torch.clamp(std_pred, min=EPS) \n",
    "    \n",
    "    # Negative log likelihood of Gaussian distribution\n",
    "    loss = torch.mean(0.5 * ((target - mean_pred) / std_pred) ** 2 + torch.log(std_pred) + 0.5 * np.log(2 * np.pi))\n",
    "    \n",
    "    if torch.isnan(loss):\n",
    "#         print('target: ',target,' mean: ', mean_pred, ' std: ',std_pred)\n",
    "        print('mean: ', mean_pred, ' std: ',std_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4b6e7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sample:\n",
    "    def __init__(self, model, env):\n",
    "        self.model = model\n",
    "        # Create the CartPole environment\n",
    "        self.env = env\n",
    "        self.df_discrete = None\n",
    "        self.df_MDP = None\n",
    "        \n",
    "    def generateSample(self, filename, num_samples, max_episode_length=200, noise = 0):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#         device = \"cpu\"\n",
    "        self.model.to(device)\n",
    "        state_size = self.env.observation_space.shape[0]\n",
    "        #state_size = 4\n",
    "        samples = []\n",
    "        sample_count = 0\n",
    "        while sample_count < num_samples:\n",
    "            state = self.env.reset()[0]\n",
    "            episode_length = 0\n",
    "\n",
    "            while episode_length <= max_episode_length:\n",
    "                action = self.env.action_space.sample()\n",
    "                input_model = list(state) + [action]\n",
    "                input_model = torch.tensor(input_model, device=device, dtype=torch.float32)\n",
    "                input_model = input_model.unsqueeze(0)\n",
    "                print(input_model)\n",
    "\n",
    "                #print(f\"Model is on device: \" + str(next(model.parameters()).device))\n",
    "                #print(f\"input_model is on device: {input_model.device}\")\n",
    "                mean_next_state, std_next_state = self.model(input_model)\n",
    "                print(\"Next State : mean, std\")\n",
    "                print(mean_next_state, std_next_state)\n",
    "            \n",
    "                \n",
    "                # Apply softplus to std_next_state to ensure it is positive\n",
    "                std_next_state = torch.nn.functional.softplus(std_next_state)\n",
    "        \n",
    "                std_next_state = torch.clamp(std_next_state, min = 0, max=1e+2)\n",
    "\n",
    "                # Create a normal distribution with the given mean and std\n",
    "                normal_dist = torch.distributions.Normal(mean_next_state, std_next_state)\n",
    "\n",
    "                # Sample from the distribution\n",
    "                next_state = normal_dist.sample()[0]\n",
    "                print(\"Next State\")\n",
    "                print(next_state)\n",
    "                \n",
    "                #print(next_state)\n",
    "                state = list(state)\n",
    "                action = [str(action)]\n",
    "                next_state = next_state.tolist()\n",
    "                next_state, reward, done = next_state[:-2], next_state[-2], next_state[-1]\n",
    "                reward = [reward]\n",
    "                #next_state = [noise*random.uniform(-1, 1)+next_state[i] for i in range(state_size)]\n",
    "                #next_state = self.add_noise(next_state)\n",
    "\n",
    "                sample = state + action + reward + next_state\n",
    "                samples.append(sample)\n",
    "                state = next_state\n",
    "                \n",
    "                sample_count = sample_count + 1\n",
    "                episode_length += 1\n",
    "                if done > 0.5 or done < -0.5:\n",
    "                    break\n",
    "#                 break\n",
    "#             break\n",
    "                    \n",
    "        df = pd.DataFrame(samples)\n",
    "        df.columns = [f'variable_{i}' for i in range(state_size)] + ['action','reward'] + [f'nx_variable_{i}' for i in range(state_size)]\n",
    "        self.df_data = df\n",
    "        df.to_csv(filename, index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da65d6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_names = ['CartPole-v1', 'MountainCarContinuous-v0', 'MountainCar-v0', 'Pendulum-v1']\n",
    "num_samples_list = ['10k', '20k', '30k', '40k', '50k']\n",
    "\n",
    "for env_name in env_names:\n",
    "\n",
    "    env = gym.make(env_name)\n",
    "    batch_size = 32\n",
    "\n",
    "\n",
    "    for num_samples in num_samples_list:\n",
    "        \n",
    "        #Initialize parameters for model\n",
    "        action = env.action_space.sample()\n",
    "\n",
    "        if isinstance(action, int):\n",
    "            input_size = env.observation_space.shape[0] + 1\n",
    "        elif isinstance(action, np.ndarray):\n",
    "            input_size = env.observation_space.shape[0] + len(action)\n",
    "\n",
    "        output_size = 2*(env.observation_space.shape[0] + 2)\n",
    "        num_layers = 3\n",
    "        num_nodes = 20\n",
    "        activation = nn.ReLU()\n",
    "        num_ensembles = 5\n",
    "        learning_rate = 0.01\n",
    "\n",
    "        model = EnsembleModel(input_size, output_size, num_layers, num_nodes, activation, num_ensembles).to(device)\n",
    "        \n",
    "        \n",
    "        model_weights_file_path = 'pets_'+ env_name + '_' + num_samples +'.pth' \n",
    "#         model_weights_file_path = 'pets_'+ env_name + '_' + num_samples + '_g=5' +'.pth' \n",
    "        model.load_state_dict(torch.load(model_weights_file_path))\n",
    "        \n",
    "        sample = Sample(model,env)\n",
    "        sample_filename = 'pets_'+ env_name + '_' + num_samples + '_sample.csv'\n",
    "#         sample_filename = 'pets_'+ env_name + '_' + num_samples + '_g=5_sample.csv'\n",
    "        sample.generateSample(num_samples = 10000, noise = 0, filename = sample_filename)\n",
    "        \n",
    "#         break\n",
    "#     break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633124ac",
   "metadata": {},
   "source": [
    "# Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21d747f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MC_Dropout_Net(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_hidden_layers, hidden_layer_nodes, activation, dropout_prob, num_network):\n",
    "        super(MC_Dropout_Net, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.hidden_layer_nodes = hidden_layer_nodes\n",
    "        self.activation = activation\n",
    "        self.num_network = num_network\n",
    "        \n",
    "        # Define the layers\n",
    "        self.input_layer = nn.Linear(input_size, hidden_layer_nodes)\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for _ in range(num_hidden_layers):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_layer_nodes, hidden_layer_nodes))\n",
    "            self.hidden_layers.append(nn.Dropout(p=dropout_prob))\n",
    "        self.output_layer = nn.Linear(hidden_layer_nodes, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        total_output = 0.0\n",
    "        for i in range(self.num_network):\n",
    "            x_temp = x\n",
    "            x_temp = self.activation(self.input_layer(x_temp))\n",
    "            for hidden_layer in self.hidden_layers:\n",
    "                x_temp = self.activation(hidden_layer(x_temp))\n",
    "            output = self.output_layer(x_temp)\n",
    "            total_output += output\n",
    "        average_output = total_output / self.num_network\n",
    "        return average_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31d69323",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sample:\n",
    "    def __init__(self, model, env):\n",
    "        self.model = model\n",
    "        # Create the CartPole environment\n",
    "        self.env = env\n",
    "        self.df_discrete = None\n",
    "        self.df_MDP = None\n",
    "        \n",
    "    def generateSample(self, filename, num_samples, max_episode_length=200, noise = 0):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(device)\n",
    "        state_size = self.env.observation_space.shape[0]\n",
    "        #state_size = 4\n",
    "        samples = []\n",
    "        sample_count = 0\n",
    "        while sample_count < num_samples:\n",
    "            state = self.env.reset()[0]\n",
    "            episode_length = 0\n",
    "\n",
    "            while episode_length <= max_episode_length:\n",
    "                action = self.env.action_space.sample()\n",
    "                input_model = list(state) + [action]\n",
    "                input_model = torch.tensor(input_model, device=device, dtype=torch.float32)\n",
    "                #print(f\"Model is on device: \" + str(next(model.parameters()).device))\n",
    "                #print(f\"input_model is on device: {input_model.device}\")\n",
    "                next_state = self.model(input_model)\n",
    "                state = list(state)\n",
    "                action = [str(action)]\n",
    "                next_state = next_state.tolist()\n",
    "                next_state, reward, done = next_state[:-2], next_state[-2], next_state[-1]\n",
    "                reward = [reward]\n",
    "                #next_state = [noise*random.uniform(-1, 1)+next_state[i] for i in range(state_size)]\n",
    "                #next_state = self.add_noise(next_state)\n",
    "\n",
    "                sample = state + action + reward + next_state\n",
    "                samples.append(sample)\n",
    "                state = next_state\n",
    "                \n",
    "                sample_count = sample_count + 1\n",
    "                episode_length += 1\n",
    "                if done > 0.5 or done < -0.5:\n",
    "                    break\n",
    "                    \n",
    "        df = pd.DataFrame(samples)\n",
    "        df.columns = [f'variable_{i}' for i in range(state_size)] + ['action','reward'] + [f'nx_variable_{i}' for i in range(state_size)]\n",
    "        self.df_data = df\n",
    "        df.to_csv(filename, index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88c2a79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "montecarlodropout_CartPole-v1_10k_sample.csv\n",
      "montecarlodropout_CartPole-v1_20k_sample.csv\n",
      "montecarlodropout_CartPole-v1_30k_sample.csv\n",
      "montecarlodropout_CartPole-v1_40k_sample.csv\n",
      "montecarlodropout_CartPole-v1_50k_sample.csv\n",
      "montecarlodropout_MountainCarContinuous-v0_10k_sample.csv\n",
      "montecarlodropout_MountainCarContinuous-v0_20k_sample.csv\n",
      "montecarlodropout_MountainCarContinuous-v0_30k_sample.csv\n",
      "montecarlodropout_MountainCarContinuous-v0_40k_sample.csv\n",
      "montecarlodropout_MountainCarContinuous-v0_50k_sample.csv\n",
      "montecarlodropout_MountainCar-v0_10k_sample.csv\n",
      "montecarlodropout_MountainCar-v0_20k_sample.csv\n",
      "montecarlodropout_MountainCar-v0_30k_sample.csv\n",
      "montecarlodropout_MountainCar-v0_40k_sample.csv\n",
      "montecarlodropout_MountainCar-v0_50k_sample.csv\n",
      "montecarlodropout_Pendulum-v1_10k_sample.csv\n",
      "montecarlodropout_Pendulum-v1_20k_sample.csv\n",
      "montecarlodropout_Pendulum-v1_30k_sample.csv\n",
      "montecarlodropout_Pendulum-v1_40k_sample.csv\n",
      "montecarlodropout_Pendulum-v1_50k_sample.csv\n"
     ]
    }
   ],
   "source": [
    "env_names = ['CartPole-v1', 'MountainCarContinuous-v0', 'MountainCar-v0', 'Pendulum-v1']\n",
    "num_samples_list = ['10k', '20k', '30k', '40k', '50k']\n",
    "\n",
    "for env_name in env_names:\n",
    "\n",
    "    env = gym.make(env_name)\n",
    "    batch_size = 32\n",
    "\n",
    "\n",
    "    for num_samples in num_samples_list:\n",
    "        \n",
    "        #Initialize parameters for model\n",
    "        action = env.action_space.sample()\n",
    "\n",
    "        if isinstance(action, int):\n",
    "            input_size = env.observation_space.shape[0] + 1\n",
    "        elif isinstance(action, np.ndarray):\n",
    "            input_size = env.observation_space.shape[0] + len(action)\n",
    "\n",
    "        output_size = env.observation_space.shape[0] + 2\n",
    "        num_hidden_layers = 3\n",
    "        hidden_layer_nodes = 20\n",
    "        activation = F.relu\n",
    "        learning_rate = 0.01\n",
    "        dropout_prob = 0.3\n",
    "        num_networks = 1\n",
    "\n",
    "\n",
    "        # Instantiate the model\n",
    "        model = MC_Dropout_Net(input_size, output_size, num_hidden_layers, hidden_layer_nodes, activation, dropout_prob, num_networks).to(device)\n",
    "\n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        model_weights_file_path = 'montecarlodropout_'+ env_name + '_' + num_samples +'.pth'\n",
    "#         model_weights_file_path = 'montecarlodropout_'+ env_name + '_' + num_samples + '_g=5' +'.pth'\n",
    "        # Save the trained model\n",
    "        model.load_state_dict(torch.load(model_weights_file_path))\n",
    "#         torch.load(model.state_dict(), model_weights_file_path)\n",
    "        \n",
    "        sample = Sample(model,env)\n",
    "        sample_filename = 'montecarlodropout_'+ env_name + '_' + num_samples + '_sample.csv'\n",
    "#         sample_filename = 'montecarlodropout_'+ env_name + '_' + num_samples + '_g=5' + '_sample.csv'\n",
    "        sample.generateSample(num_samples = 10000, noise = 0, filename = sample_filename)\n",
    "        print(sample_filename)\n",
    "        \n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec87b57",
   "metadata": {},
   "source": [
    "# Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d796a78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchbnn in /home/jeeva/anaconda3/lib/python3.11/site-packages (1.2)\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "!pip install torchbnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchbnn as bnn\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import pickle\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff69b508",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_hidden_layers, hidden_layer_nodes, activation):\n",
    "        super(BayesianNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.hidden_layer_nodes = hidden_layer_nodes\n",
    "        self.activation = activation\n",
    "        \n",
    "        # Define the layers\n",
    "#         self.input_layer = nn.Linear(input_size, hidden_layer_nodes)\n",
    "        self.input_layer = bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=input_size, out_features=hidden_layer_nodes)\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for _ in range(num_hidden_layers):\n",
    "#           self.hidden_layers.append(nn.Linear(hidden_layer_nodes, hidden_layer_nodes))\n",
    "            self.hidden_layers.append(bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=hidden_layer_nodes, out_features=hidden_layer_nodes))\n",
    "#        self.output_layer = nn.Linear(hidden_layer_nodes, output_size)\n",
    "        self.output_layer = bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=hidden_layer_nodes, out_features=output_size)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.input_layer(x))\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = self.activation(hidden_layer(x))\n",
    "        output = self.output_layer(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d8ba0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bayesian_CartPole-v1_10k_g=5_sample.csv\n"
     ]
    }
   ],
   "source": [
    "env_names = ['CartPole-v1', 'MountainCarContinuous-v0', 'MountainCar-v0', 'Pendulum-v1']\n",
    "num_samples_list = ['10k', '20k', '30k', '40k', '50k']\n",
    "\n",
    "for env_name in env_names:\n",
    "\n",
    "    env = gym.make(env_name)\n",
    "    batch_size = 32\n",
    "\n",
    "\n",
    "    for num_samples in num_samples_list:\n",
    "        \n",
    "        #Initialize parameters for model\n",
    "        action = env.action_space.sample()\n",
    "\n",
    "        if isinstance(action, int):\n",
    "            input_size = env.observation_space.shape[0] + 1\n",
    "        elif isinstance(action, np.ndarray):\n",
    "            input_size = env.observation_space.shape[0] + len(action)\n",
    "\n",
    "        output_size = env.observation_space.shape[0] + 2\n",
    "        num_hidden_layers = 3\n",
    "        hidden_layer_nodes = 20\n",
    "        activation = F.relu\n",
    "        learning_rate = 0.01\n",
    "        dropout_prob = 0.3\n",
    "        num_networks = 5\n",
    "\n",
    "        # Instantiate the model\n",
    "        model = BayesianNN(input_size, output_size, num_hidden_layers, hidden_layer_nodes, activation).to(device)\n",
    "\n",
    "        mse_loss = nn.MSELoss()\n",
    "        kl_loss = bnn.BKLLoss(reduction='mean', last_layer_only=False)\n",
    "        kl_weight = 0.01\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        model_weights_file_path = 'bayesian_'+ env_name + '_' + num_samples +'.pth' \n",
    "#         model_weights_file_path = 'bayesian_'+ env_name + '_' + num_samples + '_g=5' +'.pth'\n",
    "        # Save the trained model\n",
    "        model.load_state_dict(torch.load(model_weights_file_path))\n",
    "#         torch.load(model.state_dict(), model_weights_file_path)\n",
    "        \n",
    "        sample = Sample(model,env)\n",
    "        sample_filename = 'bayesian_'+ env_name + '_' + num_samples + '_sample.csv'\n",
    "#         sample_filename = 'bayesian_'+ env_name + '_' + num_samples + '_g=5_sample.csv'\n",
    "        sample.generateSample(num_samples = 10000, noise = 0, filename = sample_filename)\n",
    "        print(sample_filename)\n",
    "        \n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197cf12a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
