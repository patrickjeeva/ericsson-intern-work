# Project Repository for Verification of Reinforcement Learning Models: Comparing Construction of Environment Models

Welcome to the repository for our Reinforcement Learning (RL) models and associated code. This repository is organized into the following sections:

## 1. Model

This directory contains pre-trained models for various RL environments. Each environment has subdirectories for different modeling approaches and trained models.

### Structure

- **Cartpole**
  - `Bayesian`
    - Models trained on 10k, 20k, 30k, and 40k samples (`.pth` format)
  - `PETS`
    - Models trained on 10k, 20k, 30k, and 40k samples (`.pth` format)
  - `Monte Carlo Dropout`
    - Models trained on 10k, 20k, 30k, and 40k samples (`.pth` format)

- **Mountain Car**
  - `Bayesian`
    - Models trained on 10k, 20k, 30k, and 40k samples (`.pth` format)
  - `PETS`
    - Models trained on 10k, 20k, 30k, and 40k samples (`.pth` format)
  - `Monte Carlo Dropout`
    - Models trained on 10k, 20k, 30k, and 40k samples (`.pth` format)

- **Mountain Car Continuous**
  - `Bayesian`
    - Models trained on 10k, 20k, 30k, and 40k samples (`.pth` format)
  - `PETS`
    - Models trained on 10k, 20k, and 30k samples (`.pth` format)
  - `Monte Carlo Dropout`
    - Models trained on 10k, 20k, 30k, and 40k samples (`.pth` format)

- **Pendulum**
  - `Bayesian`
    - Models trained on 10k, 20k, 30k, and 40k samples (`.pth` format)
  - `PETS`
    - Models trained on 10k, 20k, 30k, and 40k samples (`.pth` format)
  - `Monte Carlo Dropout`
    - Models trained on 10k, 20k, 30k, and 40k samples (`.pth` format)

### Model Details
Each model in the `.pth` format represents a neural network trained using one of the following methods:
- **Bayesian**: Bayesian Neural Networks for uncertainty estimation.
- **PETS**: Probabilistic Ensembles with Trajectory Sampling.
- **Monte Carlo Dropout**: Models with uncertainty estimation using dropout during inference.

## 2. Code

The `Code` directory contains scripts and tools for training, evaluating, and visualizing the RL models. The following are the key components:

- **Training Scripts**: Scripts to train models for each environment using Bayesian, PETS, or Monte Carlo Dropout approaches.
- **Evaluation Scripts**: Scripts for testing and comparing model performance.
- **Utilities**: Helper functions for data preprocessing, model saving/loading, and environment setup.
- **Visualization**: Tools for plotting training curves, reward distributions, and other metrics.

### Structure

- **Create_models**
  - Creates all the PETS, Monte Carlo Dropout and Bayesian for 10k, 20k, 30k 40k, 50k samples of all mentioned environments in one go.
- **Data-to-discretised-MDP**
  - Builds MDP with input as an data excel file and discretization.
- **Discretization-of-columns**
  - Discretizes the given excel data file and stores it.
- **PETS_env, monte_carlo_dropout_env, bayesian_env**
  - Creates their respective individual models.
- **onnx_to_constraints**
  - Loads an ONNX model, extracts its weights and structure, maps its layers, generates symbolic constraints using Z3 SMT solver for verification, and writes these constraints to an SMT-LIB file for formal verification purposes.
- **Sampling-from-MDP-multi-column, Sampling-from-MDP-single-column**
  - Generates random samples from MDPs and compare empirical transition probabilities of these samples with original MDP.
- **env_sample_generation**
  - Generate 10k, 20k, 30k, 40k, 50k training samples from Cartpole, Mountain Car, Mountain Car Continuous and Pendulum Gym environments.
  - This generates the samples using which the models are trained. Also ground truth MDPs are constructed using this.
- **generate_samples_from_models**
  - Generate 10k, 20k, 30k, 40k, 50k training samples from different model architectures trained on Cartpole, Mountain Car, Mountain Car Continuous and Pendulum.
  - This is going to be used to construct MDPs which can be compared with the ground truth.
- **env_discretisedMDP**
  - Builds MDP based on discretized samples generated from mentioned Gym environment. Provides capability for MDP visualization.
- **cartpole_discretisedMDP**
  - Builds MDP based on discretized samples generated by Cartpole environment.
- **graphviz_plot_mdp**
  - Generates a graphical visualization of the MDP as a directed graph, showing states, actions, and transitions using graphviz.
- **networkx_plot_mdp**
  - Generates a graphical visualization of the MDP as a directed graph, showing states, actions, and transitions using Networkx.
- **state_var_graph**
  - Loads PETS, Monte Carlo Dropout, and Bayesian Neural Networks on mentioned RL environment using pre-trained to create next state variable graph.

### Code Flow
- Use **env_sample_generation** to create the ground truth samples.
- **Create_models** is used to build all the models using the generated ground truth samples.
- **generate_samples_from_models** generates samples from the models created.

## Getting Started

1. **Clone the Repository**:
   ```bash
   git clone <repository_url>
   cd <repository_name>
   ```

2. **Install Dependencies**:
   Ensure you have Python 3.7+ and install the required packages:
   ```bash
   pip install -r requirements.txt
   ```

3. **Navigate to Models**:
   Explore the pre-trained models in the `Model` directory.

4. **Run Training/Evaluation**:
   Use the scripts in the `Notebook` directory to train or evaluate models. Example : Create_models creates the models in one go.

## Contributions

Contributions are welcome! Please fork the repository and create a pull request with your changes.

## License

This project is licensed under the MIT License. See the `LICENSE` file for details.

## Contact

For any questions or feedback, please reach out via email or open an issue in the repository.

